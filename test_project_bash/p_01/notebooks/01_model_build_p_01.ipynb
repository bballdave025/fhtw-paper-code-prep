{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31694550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 22:50:00.812238: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-03 22:50:02.463508: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-03 22:50:02.463574: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-03 22:50:02.470931: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-03 22:50:03.439508: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-03 22:50:07.503792: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#import os, random, numpy as np, tensorflow as tf\n",
    "#os.environ[\"PYTHONHASHSEED\"]=\"137\";\n",
    "#random.seed(137);\n",
    "#np.random.seed(137);\n",
    "#tf.random.set_seed(137)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269c67fd-6f6d-444b-ad4f-437daee55148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-03 22:58:27.095669: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-03 22:58:27.159910: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-03 22:58:27.159957: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-03 22:58:27.160003: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-03 22:58:27.171184: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-03 22:58:28.940826: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.18\n",
      "Executable: /home/bballdave025/miniforge3/envs/vanilla_cnn/bin/python\n",
      "Conda prefix: /home/bballdave025/miniforge3/envs/vanilla_cnn\n",
      "TF: 2.14.0\n"
     ]
    }
   ],
   "source": [
    "import sys, os, platform, tensorflow as tf\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"Executable:\", sys.executable)\n",
    "print(\"Conda prefix:\", os.environ.get(\"CONDA_PREFIX\"))\n",
    "print(\"TF:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207dfb81-45e9-46ec-925b-0d28816b3ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, numpy as np, tensorflow as tf\n",
    "os.environ[\"PYTHONHASHSEED\"]=\"137\";\n",
    "random.seed(137);\n",
    "np.random.seed(137);\n",
    "tf.random.set_seed(137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8127fa1b-28ad-4c84-a2af-9e2613b4390b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Intra op parallelism cannot be modified after initialization.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Import TF only after env vars are set\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreading\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_intra_op_parallelism_threads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTF_NUM_INTRAOP_THREADS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mthreading\u001b[38;5;241m.\u001b[39mset_inter_op_parallelism_threads(\u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF_NUM_INTEROP_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m######## From first try, still keep #############\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Minimal CIFAR-10 Q&R cell — seed=137, CPU, saves CSV + JSON + prints [DONE]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/vanilla_cnn/lib/python3.10/site-packages/tensorflow/python/framework/config.py:129\u001b[0m, in \u001b[0;36mset_intra_op_parallelism_threads\u001b[0;34m(num_threads)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.threading.set_intra_op_parallelism_threads\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mset_intra_op_parallelism_threads\u001b[39m(num_threads):\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Set number of threads used within an individual op for parallelism.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m  Certain operations like matrix multiplication and reductions can utilize\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    num_threads: Number of parallel threads\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m   \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintra_op_parallelism_threads\u001b[49m \u001b[38;5;241m=\u001b[39m num_threads\n",
      "File \u001b[0;32m~/miniforge3/envs/vanilla_cnn/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1969\u001b[0m, in \u001b[0;36mContext.intra_op_parallelism_threads\u001b[0;34m(self, num_threads)\u001b[0m\n\u001b[1;32m   1966\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1969\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1970\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntra op parallelism cannot be modified after initialization.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1972\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intra_op_parallelism_threads \u001b[38;5;241m=\u001b[39m num_threads\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Intra op parallelism cannot be modified after initialization."
     ]
    }
   ],
   "source": [
    "# --- CIFAR-10 cache + quieter TF (paste at very top) ---\n",
    "import os, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Quieter + modest threads (optional)\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"4\")\n",
    "os.environ.setdefault(\"TF_NUM_INTEROP_THREADS\", \"2\")\n",
    "os.environ.setdefault(\"TF_NUM_INTRAOP_THREADS\", \"4\")\n",
    "\n",
    "# Use project-local cache under $TAGDIR/datasets; fall back to ~/.keras/datasets if present\n",
    "tagdir = Path(os.environ.get(\"TAGDIR\", Path.cwd()))\n",
    "if tagdir.name == \"notebooks\":\n",
    "    tagdir = tagdir.parent\n",
    "os.environ.setdefault(\"KERAS_HOME\", str(tagdir))  # Keras will use $KERAS_HOME/datasets\n",
    "proj_cache = Path(os.environ[\"KERAS_HOME\"]) / \"datasets\"\n",
    "proj_cache.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "home_cache = Path.home() / \".keras\" / \"datasets\"\n",
    "# If project cache lacks CIFAR but home cache has it, mirror it over:\n",
    "candidates = [(\"cifar-10-python.tar.gz\", True), (\"cifar-10-batches-py\", False)]\n",
    "if home_cache.exists() and not any((proj_cache / name).exists() for name, _ in candidates):\n",
    "    for name, is_file in candidates:\n",
    "        src = home_cache / name\n",
    "        if src.exists():\n",
    "            dst = proj_cache / src.name\n",
    "            if is_file:\n",
    "                shutil.copy2(src, dst)\n",
    "            else:\n",
    "                shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "\n",
    "# Import TF only after env vars are set\n",
    "import tensorflow as tf\n",
    "tf.config.threading.set_intra_op_parallelism_threads(int(os.environ[\"TF_NUM_INTRAOP_THREADS\"]))\n",
    "tf.config.threading.set_inter_op_parallelism_threads(int(os.environ[\"TF_NUM_INTEROP_THREADS\"]))\n",
    "\n",
    "\n",
    "\n",
    "######## From first try, still keep #############\n",
    "\n",
    "# Minimal CIFAR-10 Q&R cell — seed=137, CPU, saves CSV + JSON + prints [DONE]\n",
    "import os, json, time, random, csv\n",
    "from pathlib import Path\n",
    "import numpy as np, tensorflow as tf\n",
    "\n",
    "# Force CPU (optional; harmless if no GPU)\n",
    "os.environ.setdefault(\"CUDA_VISIBLE_DEVICES\", \"\")\n",
    "\n",
    "# Repro-ish seed\n",
    "SEED = 137\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "# Resolve TAGDIR robustly\n",
    "tagdir_env = os.environ.get(\"TAGDIR\", \"\")\n",
    "tagdir = Path(tagdir_env) if tagdir_env else Path.cwd()\n",
    "if tagdir.name == \"notebooks\":  # launched notebook inside TAGDIR/notebooks\n",
    "    tagdir = tagdir.parent\n",
    "\n",
    "# Outputs\n",
    "out_dir = tagdir / \"outputs\"\n",
    "csv_dir = out_dir / \"csv_logs\"\n",
    "csv_dir.mkdir(parents=True, exist_ok=True)\n",
    "ts = time.strftime(\"%Y%m%dT%H%M%S\")\n",
    "\n",
    "# Data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test  = x_test.astype(\"float32\") / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test  = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Tiny CNN (fast on CPU)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\", input_shape=(32,32,3)),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(), tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(), tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"), tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=3, batch_size=64, validation_split=0.1, verbose=2)\n",
    "\n",
    "# Test + artifacts\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "csv_path = csv_dir / f\"train_history_seed{SEED}_{ts}.csv\"\n",
    "with open(csv_path, \"w\", newline=\"\") as f:\n",
    "    keys = list(hist.history.keys())\n",
    "    writer = csv.writer(f); writer.writerow([\"epoch\"] + keys)\n",
    "    for i in range(len(hist.history[keys[0]])):\n",
    "        writer.writerow([i+1] + [hist.history[k][i] for k in keys])\n",
    "\n",
    "summary_path = out_dir / f\"test_summary_seed{SEED}_{ts}.json\"\n",
    "with open(summary_path, \"w\") as f:\n",
    "    json.dump({\"seed\": SEED, \"timestamp\": ts, \"test_accuracy\": float(test_acc)}, f, indent=2)\n",
    "\n",
    "print(f\"[DONE] test_acc={test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eb361f-cca6-4a24-a9bc-8c0ae99baf9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
